{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from os import chdir\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from V2I import video2image\n",
    "import datetime\n",
    "from moviepy.editor import *\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "from keras.models import load_model\n",
    "my_vgg = load_model('finetuned_vgg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-30 04:12:59.749015\n",
      "1 videos done.\n",
      "2 videos done.\n",
      "3 videos done.\n",
      "4 videos done.\n",
      "5 videos done.\n",
      "6 videos done.\n",
      "7 videos done.\n",
      "8 videos done.\n",
      "9 videos done.\n",
      "10 videos done.\n",
      "2018-07-30 04:13:08.435781\n"
     ]
    }
   ],
   "source": [
    "height =128\n",
    "width =128\n",
    "seq_len=30\n",
    "ms = 200\n",
    "\n",
    "video_wd ='D:\\\\tobigs2\\\\kakao\\\\Real_Testset\\\\'\n",
    "model_saving_wd = 'D:\\\\tobigs2\\\\kakao\\\\Model 1\\\\5. Not Ensemble\\\\Model_Saved\\\\'\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "data=np.zeros(128*128*3*30).reshape([1,30,128,128,3])\n",
    "label = []\n",
    "count = []\n",
    "i=0\n",
    "for path, dir, files in os.walk(video_wd):\n",
    "    if path == video_wd + 'No_Fall':\n",
    "        idx = 0 # no _fall\n",
    "    else :\n",
    "        idx= 1 # Fall\n",
    "    for file in files: \n",
    "        wd_file = path + '\\\\' + file\n",
    "        cnt, clips = video2image(wd = video_wd,\n",
    "                                video = wd_file,\n",
    "                                width =width,\n",
    "                                height = height,\n",
    "                                ms= ms,\n",
    "                                seq_len = seq_len,\n",
    "                                standard = 50)\n",
    "        data = np.concatenate([data, np.array(clips).reshape([1,30,128,128,3])], axis=0)\n",
    "        label.append(idx)\n",
    "        count.append(cnt)\n",
    "        i+=1\n",
    "        print('{} videos done.' . format(i))\n",
    "label = np.array(label)\n",
    "count = np.array(count)\n",
    "count[count>seq_len] = seq_len\n",
    "data = data[1:]\n",
    "ch_to_idx = {'Fall':1, 'No_Fall':0}\n",
    "n_videos = len(data)\n",
    "n_class = len(ch_to_idx)\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-30 04:14:31.167340\n",
      "2018-07-30 04:14:31.778702\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "\n",
    "def RightToLeft(x):\n",
    "    result=np.zeros(30*128*128*3).reshape([1,30,128,128,3])\n",
    "    for video in x:\n",
    "        photos_per_video =[]\n",
    "        for img in video:\n",
    "            fliped_img = np.fliplr(img)\n",
    "            photos_per_video.append(fliped_img)\n",
    "        result= np.concatenate([result,np.array(photos_per_video).reshape([1,30,128,128,3])], axis=0)\n",
    "    return(result[1:])\n",
    "aug_data = np.array(RightToLeft(data))\n",
    "\n",
    "data = np.concatenate([data,aug_data],axis=0)\n",
    "count = np.concatenate([count,count],axis=0)\n",
    "label = np.concatenate([label,label],axis=0)\n",
    "\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "data_ftmap = np.zeros(30*4*4*512).reshape([1,30,4*4*512])\n",
    "for i in range(len(data)):\n",
    "    data_ftmap = np.concatenate([data_ftmap, my_vgg.predict(data[i]).reshape(1,seq_len,-1)], axis=0) \n",
    "    if i %300 ==0:\n",
    "        print(i)\n",
    "\n",
    "data_ftmap = data_ftmap[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 30, 8192)\n",
      "(20,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(data_ftmap))\n",
    "print(np.shape(count))\n",
    "print(np.shape(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = data_ftmap\n",
    "test_y = label\n",
    "test_count = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 30, 8192)\n",
      "(20,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(test_x))\n",
    "print(np.shape(test_y))\n",
    "print(np.shape(test_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from D:\\tobigs2\\kakao\\Model 1\\5. Not Ensemble\\Model_Saved\\0_Model.ckpt\n",
      "test accuracy :  0.4\n",
      "[1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 0]\n",
      "[14 28 28 26 30 28 30 23 30 20 14 28 28 26 30 28 30 23 30 20]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0  0  1\n",
       "row_0      \n",
       "0.0    3  7\n",
       "1.0    5  5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_result=[]\n",
    "batch_size =50\n",
    "trying=0 # 첫번쨰모델로만 성능을 확인할거임\n",
    "\n",
    "tf.reset_default_graph()\n",
    "test_graph = tf.Graph()\n",
    "with tf.Session(graph=test_graph) as sess:\n",
    "    loader = tf.train.import_meta_graph(model_saving_wd + str(trying)+ '_Model.ckpt.meta')\n",
    "    loader.restore(sess, model_saving_wd + str(trying)  +  '_Model.ckpt')\n",
    "    \n",
    "    LSTM_x = test_graph.get_tensor_by_name(name='LSTM_x:0')\n",
    "    LSTM_y = test_graph.get_tensor_by_name(name='LSTM_y:0')\n",
    "    LSTM_count = test_graph.get_tensor_by_name(name='LSTM_count:0')\n",
    "    pred= test_graph.get_tensor_by_name(name='pred:0')\n",
    "    acc= test_graph.get_tensor_by_name(name='acc:0')\n",
    "    #L_2= loaded_graph.get_tensor_by_name(name='L_2:0')\n",
    "\n",
    "    for i in range(int(len(test_x)/batch_size )+1):\n",
    "        if i == int(n_videos/batch_size ): # 배치 다돌고 나머지 처리할떄 \n",
    "            batch_test_x = test_x[i*batch_size:]\n",
    "            batch_label = test_y[i*batch_size:]\n",
    "            batch_count = test_count[i*batch_size:]\n",
    "            \n",
    "        else:\n",
    "            batch_test_x = test_x[i*batch_size:(i+1)*batch_size]\n",
    "            batch_label = test_y[i*batch_size:(i+1)*batch_size]\n",
    "            batch_count = test_count[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "        print('test accuracy : ', sess.run(acc, feed_dict={LSTM_x:batch_test_x,\n",
    "                                                           LSTM_y:batch_label,\n",
    "                                                           LSTM_count:batch_count}))\n",
    "        prediction =  sess.run(pred,  feed_dict={LSTM_x:batch_test_x,\n",
    "                                                 LSTM_count:batch_count})\n",
    "        print(batch_label)\n",
    "        print(batch_count)\n",
    "\n",
    "        total_result += list(prediction)\n",
    "\n",
    "pd.crosstab(np.array(total_result), test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
