{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from os import chdir\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from V2I import video2image\n",
    "import datetime\n",
    "from moviepy.editor import *\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "height =128\n",
    "width =128\n",
    "seq_len=30\n",
    "ms = 200\n",
    "\n",
    "video_wd ='D:\\\\tobigs2\\\\kakao\\\\Trainset\\\\'\n",
    "model_saving_wd = 'D:\\\\tobigs2\\\\kakao\\\\Model 1\\\\5. Not Ensemble\\\\Model_Saved\\\\'\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "data=np.zeros(128*128*3*30).reshape([1,30,128,128,3])\n",
    "label = []\n",
    "count = []\n",
    "i=0\n",
    "for path, dir, files in os.walk(video_wd):\n",
    "    if path == video_wd + 'No_Fall':\n",
    "        idx = 0 # no _fall\n",
    "    else :\n",
    "        idx= 1 # Fall\n",
    "    for file in files: \n",
    "        wd_file = path + '\\\\' + file\n",
    "        cnt, clips = video2image(wd = video_wd,\n",
    "                                video = wd_file,\n",
    "                                width =width,\n",
    "                                height = height,\n",
    "                                ms= ms,\n",
    "                                seq_len = seq_len,\n",
    "                                standard = 50)\n",
    "        data = np.concatenate([data, np.array(clips).reshape([1,30,128,128,3])], axis=0)\n",
    "        label.append(idx)\n",
    "        count.append(cnt)\n",
    "        i+=1\n",
    "        print('{} videos done.' . format(i))\n",
    "label = np.array(label)\n",
    "count = np.array(count)\n",
    "count[count>seq_len] = seq_len\n",
    "data = data[1:]\n",
    "ch_to_idx = {'Fall':1, 'No_Fall':0}\n",
    "n_videos = len(data)\n",
    "n_class = len(ch_to_idx)\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_videos = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(962, 30, 128, 128, 3)\n",
      "(962,)\n",
      "(962,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(data))\n",
    "print(np.shape(count))\n",
    "print(np.shape(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(962, 30, 128, 128, 3)\n",
      "(962,)\n",
      "(962,)\n"
     ]
    }
   ],
   "source": [
    "idx = np.arange(len(data));np.random.shuffle(idx)\n",
    "\n",
    "train_x = data[idx]\n",
    "train_y = label[idx]\n",
    "train_count = count[idx]\n",
    "\n",
    "print(np.shape(train_x))\n",
    "print(np.shape(train_y))\n",
    "print(np.shape(train_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 386, 0: 576})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End to End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### LSTM Graph\n",
    "n_param = height * width * 3\n",
    "hidden_dim =96\n",
    "n_stack = 3\n",
    "n_class=len(ch_to_idx)\n",
    "n_epoch = 30\n",
    "batch_size = 14\n",
    "lr = 1e-05\n",
    "n_batches = int(len(train_x)/batch_size) # 20개짜리 데이터 뱃치셋을 넣는거임 \n",
    "\n",
    "tf.reset_default_graph()\n",
    "train_graph = tf.Graph()\n",
    "\n",
    "#Building the graph\n",
    "with train_graph.as_default():\n",
    "    LSTM_x = tf.placeholder(tf.float32, shape=[None, seq_len, height, width, 3], name='LSTM_x') \n",
    "    LSTM_y = tf.placeholder(tf.int32, shape=[None], name='LSTM_y')\n",
    "    LSTM_count = tf.placeholder(tf.int32, shape=[None], name='LSTM_count')\n",
    "    is_training = tf.placeholder(tf.bool, name='is_training' )\n",
    "    dropout_ratio = tf.placeholder(tf.float32, name='dropout_ratio')\n",
    "    \n",
    "    w1 = tf.Variable(tf.random_normal(shape=[3,3,3,32], stddev=0.01), name = \"W1\") # shape !!!!!!!!!!\n",
    "    CNN_x = tf.reshape(LSTM_x, shape=[-1,height,width,3])\n",
    "    L1 = tf.nn.conv2d(input= CNN_x, filter= w1, strides=[1,1,1,1], padding='SAME', name=\"L1\")\n",
    "    L1 = tf.nn.relu(L1)\n",
    "    L1 = tf.nn.dropout(L1,dropout_ratio)\n",
    "    L1 = tf.contrib.layers.batch_norm(L1, is_training=is_training) # batch normal, dropout, layer 추가 !!\n",
    "    L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1],  strides= [1,2,2,1], padding='SAME')\n",
    "    \n",
    "    w1_1 = tf.Variable(tf.random_normal(shape=[3,3,32,32], stddev=0.01), name = \"WW\") # shape !!!!!!!!!!\n",
    "    L2 = tf.nn.conv2d(input=L1, filter=w1_1, strides=[1,1,1,1], padding='SAME', name=\"L2\")\n",
    "    L2 = tf.nn.relu(L2)\n",
    "    L2 = tf.nn.dropout(L2, dropout_ratio)\n",
    "    L2 = tf.contrib.layers.batch_norm(L2, is_training=is_training) # batch normal, dropout, layer 추가 !!\n",
    "    L2 = tf.nn.max_pool(L2, ksize=[1,2,2,1],  strides= [1,2,2,1], padding='SAME')\n",
    "    L2_flat = tf.reshape(L2, shape=[-1,int(height/4*width/4*32)])  # 클래스를 다섯개로 만들어서 씨엔엔에 넣어보기도하자\n",
    "    \n",
    "    w2 = tf.get_variable(shape=[height/4*width/4*32,5], initializer= tf.contrib.layers.xavier_initializer(), name = \"w2\") \n",
    "    b = tf.Variable(tf.random_normal(shape = [5]))\n",
    "    logits = tf.matmul(L2_flat , w2) + b\n",
    "    logits = tf.reshape(logits, shape=[-1,seq_len,5])\n",
    "    logits = tf.identity(logits,'logits')\n",
    "\n",
    "    fw_cell = tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.LSTMCell(num_units= hidden_dim, state_is_tuple=True) for _ in range(n_stack)], state_is_tuple=True)\n",
    "    #bw_cell = tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.LSTMCell(num_units= hidden_dim, state_is_tuple=True) for _ in range(n_stack)], state_is_tuple=True)\n",
    "    outputs, state = tf.nn.dynamic_rnn(fw_cell, dtype=tf.float32, inputs= logits, sequence_length=LSTM_count) # batch로 하면 여기서 걸리네 ... n_frame_list를 뱃치를 만든 인덱스에 맞게 그때그때 바꿀수도 없고 \n",
    "    #outputs = tf.concat(outputs, 2)\n",
    "    outputs = tf.reshape(outputs,shape = [-1,seq_len*hidden_dim])\n",
    "\n",
    "#     last_index = tf.shape(outputs)[1]-1  # -1 붙여줘야 ! \n",
    "#     output_rs = tf.transpose(outputs,[1,0,2])# Treshape the output to [sequence_length,batch_size,num_units]\n",
    "#     last_states = tf.nn.embedding_lookup(output_rs,last_index)# Last state of all batches\n",
    "#     last_states = tf.identity(last_states, 'last_states')\n",
    "\n",
    "    LSTM_w_1 = tf.get_variable(shape=[seq_len*hidden_dim, 256],name='LSTM_w_1') # 전체아웃풋을 함 넣어볼까 ..\n",
    "   # LSTM_w_1 = tf.get_variable(shape=[hidden_dim, 64],name='LSTM_w_1') \n",
    "    LSTM_b_1 = tf.get_variable(shape=[256],name='LSTM_b_1')\n",
    "    LSTM_w_2 = tf.get_variable(shape=[256,n_class], name='LSTM_w_2') # 0 ,1 (안쓰러짐 ,쓰러짐)\n",
    "    LSTM_b_2 = tf.get_variable(shape=[n_class], name='LSTM_b_2')\n",
    "    #param_list = [ LSTM_w_1, LSTM_b_1, LSTM_w_2, LSTM_b_2]\n",
    "    L_1 = tf.add(tf.matmul(outputs, LSTM_w_1),LSTM_b_1) # 굿 \n",
    "    L_1 = tf.nn.relu(L_1)\n",
    "    L_1 = tf.nn.dropout(L_1, dropout_ratio) # tf.layers.dropout() >> this function has training parameter.\n",
    "    L_1 = tf.contrib.layers.batch_norm(L_1, is_training = is_training)\n",
    "    L_2 = tf.add(tf.matmul(L_1,LSTM_w_2),LSTM_b_2)\n",
    "    L_2 = tf.identity(L_2, name=\"L_2\")\n",
    "    weights = tf.ones(shape=[batch_size, seq_len])\n",
    "    #loss = tf.contrib.seq2seq.sequence_loss(logits=L_2, targets=tf.cast(tf.one_hot(LSTM_y, depth=n_class), tf.int32), weights=weights)\n",
    "    loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(logits=L_2, labels=tf.reshape(tf.one_hot(LSTM_y, depth=n_class), [-1,2])))\n",
    "    train = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)\n",
    "\n",
    "    pred = tf.cast(tf.argmax(L_2, axis=1), tf.float32, name='pred')\n",
    "    acc = tf.reduce_mean(tf.cast(tf.equal(pred,tf.cast(LSTM_y, tf.float32)), dtype=tf.float32))\n",
    "    acc = tf.identity(acc, name='acc')\n",
    "   # saver = tf.train.Saver(tf.global_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ 0  th MDOEL ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
      "2018-08-02 00:50:19.485525\n",
      "-------------------------------- Epoch:  0 --------------------------------\n",
      "Loss :  8.677575\n",
      "col_0  0  1\n",
      "row_0      \n",
      "0.0    6  2\n",
      "1.0    1  5\n",
      "Accuracy :  0.78571427\n",
      "-------------------------------- Epoch:  1 --------------------------------\n",
      "Loss :  10.141666\n",
      "col_0  0  1\n",
      "row_0      \n",
      "0.0    5  5\n",
      "1.0    0  4\n",
      "Accuracy :  0.71428573\n",
      "-------------------------------- Epoch:  2 --------------------------------\n",
      "Loss :  3.1842518\n",
      "col_0   0  1\n",
      "row_0       \n",
      "0.0    11  0\n",
      "1.0     1  2\n",
      "Accuracy :  0.9285714\n",
      "-------------------------------- Epoch:  3 --------------------------------\n",
      "Loss :  5.749964\n",
      "col_0  0  1\n",
      "row_0      \n",
      "0.0    8  0\n",
      "1.0    2  4\n",
      "Accuracy :  0.9285714\n",
      "-------------------------------- Epoch:  4 --------------------------------\n",
      "Loss :  0.34442765\n",
      "col_0  0  1\n",
      "row_0      \n",
      "0.0    8  0\n",
      "1.0    0  6\n",
      "Accuracy :  0.9285714\n",
      "-------------------------------- Epoch:  5 --------------------------------\n",
      "Loss :  0.13500026\n",
      "col_0  0  1\n",
      "row_0      \n",
      "0.0    8  0\n",
      "1.0    0  6\n",
      "Accuracy :  1.0\n",
      "-------------------------------- Epoch:  6 --------------------------------\n",
      "Loss :  1.341695\n",
      "col_0  0  1\n",
      "row_0      \n",
      "0.0    9  0\n",
      "1.0    0  5\n",
      "Accuracy :  1.0\n",
      "-------------------------------- Epoch:  7 --------------------------------\n",
      "Loss :  1.8612599\n",
      "col_0  0  1\n",
      "row_0      \n",
      "0.0    7  1\n",
      "1.0    0  6\n",
      "Accuracy :  0.9285714\n",
      "-------------------------------- Epoch:  8 --------------------------------\n",
      "Loss :  0.48976424\n",
      "col_0  0  1\n",
      "row_0      \n",
      "0.0    7  0\n",
      "1.0    0  7\n",
      "Accuracy :  1.0\n",
      "-------------------------------- Epoch:  9 --------------------------------\n",
      "Loss :  2.3665218\n",
      "col_0  0  1\n",
      "row_0      \n",
      "0.0    9  0\n",
      "1.0    1  4\n",
      "Accuracy :  0.9285714\n",
      "2018-08-02 01:54:33.239489\n"
     ]
    }
   ],
   "source": [
    "# LSTM training\n",
    "for trying in range(1): # Ensemble ! \n",
    "    #smp_idx = np.random.choice(len(data),len(data),replace=True)\n",
    "    smp_idx = np.arange(len(train_x))\n",
    "    print('ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ', trying, ' th MDOEL ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ')\n",
    "    print(datetime.datetime.now()) \n",
    "    with tf.Session(graph=train_graph) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(n_epoch):\n",
    "            batch_idx_start = 0\n",
    "            total_idx = np.arange(len(train_x)) ; np.random.shuffle(total_idx)\n",
    "            for i in range(n_batches):\n",
    "                batch_idx_end = batch_idx_start + batch_size\n",
    "                batch_idx = total_idx[batch_idx_start:batch_idx_end]\n",
    "                batch_x = train_x[smp_idx][batch_idx]\n",
    "                batch_y = train_y[smp_idx][batch_idx]\n",
    "                batch_count = train_count[smp_idx][batch_idx]\n",
    "                sess.run(train, feed_dict={LSTM_x:batch_x, \n",
    "                                           LSTM_y:batch_y,\n",
    "                                          LSTM_count:batch_count,\n",
    "                                          is_training:True,\n",
    "                                          dropout_ratio:0.5})  \n",
    "                batch_idx_start = batch_idx_end\n",
    "\n",
    "            print('--------------------------------', 'Epoch: ', epoch , '--------------------------------')  \n",
    "\n",
    "            print('Loss : ', sess.run(loss, feed_dict={LSTM_x:batch_x,\n",
    "                                                       LSTM_y:batch_y,\n",
    "                                                      LSTM_count:batch_count,\n",
    "                                                      is_training:True,\n",
    "                                                      dropout_ratio:0.5})) # per epoch \n",
    "            print(pd.crosstab(sess.run(pred, feed_dict={LSTM_x:batch_x,\n",
    "                                                       LSTM_count:batch_count,\n",
    "                                                       is_training:True,\n",
    "                                                      dropout_ratio:0.5}),\n",
    "                              batch_y))\n",
    "            print('Accuracy : ', sess.run(acc, feed_dict={LSTM_x: batch_x,\n",
    "                                                          LSTM_y: batch_y,\n",
    "                                                         LSTM_count:batch_count,\n",
    "                                                         is_training:True,\n",
    "                                                      dropout_ratio:0.5}))\n",
    "            saver = tf.train.Saver(var_list=tf.global_variables())\n",
    "            saver.save(sess, save_path= model_saving_wd + str(trying) + 'th try-' +'Model.ckpt')\n",
    "\n",
    "    print(datetime.datetime.now())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
